# Master Roadmap to V1.0 — Project Miri

**Reference:** `Atomic_PRD_V2.2.md`, `AGENTS.md`, current backend/frontend implementation.

**Current state:** Frontend calls backend `POST /api/shots/generate`; webhooks mounted; VersionRepository and RedisPublisher are stubs; Socket.io server exists but is not attached to the running HTTP server; no Firestore/Redis persistence; no end-to-end image display.

---

## Phase 1: Persistence & Real-Time (Close the Loop) ✅

**Objective:** Replace persistence and pub/sub stubs so that a shot generation started from the UI is stored, FAL can call back, the app updates state, and the UI can show completion via real-time events.

**Required tasks:**

- [x] **VersionRepository (Firestore):** Implement `insertVersion`…
- [x] **OrchestrationService:** Use the returned `versionId`…
- [x] **RedisPublisher:** Implement `publishShotUpdated`…
- [x] **GenerationController:** Await `OrchestrationService.startGenerationFlow`…
- [x] **Server entry (backend):** Create an HTTP server with `http.createServer(app)`…
- [x] **Frontend – real-time UI:** In the screen that starts generation, connect the existing socket…
- [x] **Frontend – display image when ready:** When a `SHOT_UPDATED` event indicates `IMAGE_READY`…

---

## Phase 2: Redis Emission & WebSocket Tests

**Objective:** Fulfil backend Implementation Plan items 4.2 and 4.3: webhooks actually emit via Redis, and WebSocket behaviour is covered by tests.

**Required tasks:**

- [ ] **RedisPublisher:** Ensure `FalWebhookController` and `VideoWebhookController` call it…
- [ ] **Tests:** Add or extend tests that simulate a WebSocket client connecting…

---

## Phase 3: Video Pipeline & Python Renderer

**Objective:** Support the full shot lifecycle through to video…

**Required tasks:**

- [ ] **OrchestrationService / video path:** Add a flow that submits a video job…
- [ ] **VideoWebhookController:** Ensure it reads `versionId`, calls `updateVersionStatus`…
- [ ] **Python renderer – server:** Set up a Flask or FastAPI app…
- [ ] **Python renderer – moviepy:** Implement logic that stitches clips…
- [ ] **Backend – call renderer:** When all shots are COMPLETED, call the Python renderer…

---

## Phase 4: UI Completeness (Time-Travel & Chat Parity)

**Objective:** Align the UI with PRD Section 8: time-travel version browsing and Chat parity.

**Required tasks:**

- [ ] **Time-travel (version browsing):** Add a Dashboard UI…
- [ ] **Chat parity:** Extend the Chat UI and backend so every action can be done via chat…
- [ ] **Multiple parallel conversations:** Support multiple independent generation streams…
- [ ] **Loading and RTL:** Ensure loading states are clear and RTL is preserved…

---

## Phase 5: Dynamic Scene Engine & LLM Integration

**Objective:** Implement the "Blank Slate" and script-driven pipeline…

**Required tasks:**

- [ ] **Blank Slate – audio analysis:** Integrate Gemini 1.5 Pro to analyze MP3 and lyrics…
- [ ] **Story iteration:** Use LLM to conduct an interview to refine the story…
- [ ] **Scene breakdown:** Divide script into Scenes with strict timestamps and pre-generate assets…
- [ ] **Shot generation from scenes:** Generate strict JSON prompts…
- [ ] **Metadata tagging:** Ensure every prompt includes identification prefix…
- [ ] **Localization (Hebrew):** Translate prompts/labels to Hebrew…
- [ ] **Photometric precision:** Enforce HEX color codes in JSON…

---

## Phase 6: Resilience & Production Readiness

**Objective:** Harden external integrations and prepare for production.

**Required tasks:**

- [ ] **Circuit Breaker:** Implement the Circuit Breaker pattern around external APIs…
- [ ] **Configuration:** Ensure API keys are server-side only…
- [ ] **Deployment:** Prepare for GCP Cloud Run…

---

## Phase 7: Advanced Consistency & Rulebook (V1.0 Polish)

**Objective:** Implement multi-reference continuity, targeted editing, and the Active Rulebook.

**Required tasks:**

- [ ] **FLUX.2 multi-reference:** Support `image_urls` array for pre-generated images…
- [ ] **Scene-level SEED:** Assign a random, uniform SEED per scene…
- [ ] **Targeted editing:** Integrate `flux-2-edit` for short imperative commands…
- [ ] **KLING anchor frames:** Ensure video path explicitly sends Start/End frames…
- [ ] **Active Rulebook:** Store rejections, use Gemini Vision to analyze failure, index in Vector Search…
- [ ] **Conversational QA:** Allow user to explain why image failed to auto-fix…

---

*Last updated: Phase 1 completed. Proceed to Phase 2 when approved.*
